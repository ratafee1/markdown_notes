

# 启动zookeeper，hadoop，spark

cd /export/servers/zookeeper-3.4.9/bin

zkServer.sh start

start-dfs.sh	

start-yarn.sh

hive --service metastore &

hive --service hiveserver2 &

cd /export/servers/spark
sbin/start-all.sh

# 启动zookeeper

cd /export/servers/zookeeper-3.4.9/bin

zkServer.sh start



![image-20191221123338642](C:\Users\app\AppData\Roaming\Typora\typora-user-images\image-20191221123338642.png)



![image-20191221123433619](C:\Users\app\AppData\Roaming\Typora\typora-user-images\image-20191221123433619.png)





# 启动hive

hive --service metastore &

hive --service hiveserver2 &



# 启动impala

主节点node-3启动以下三个服务进程

service impala-state-store start

service impala-catalog start

service impala-server start

 从节点启动node-1与node-2启动impala-server

service  impala-server  start

 查看impala进程是否存在

ps -ef | grep impala





# sqoop测试连接

~~~
bin/sqoop list-databases \
--connect jdbc:mysql://localhost:3306/ \
--username root --password 123456
~~~



# flume

![image-20191221125631981](C:\Users\app\AppData\Roaming\Typora\typora-user-images\image-20191221125631981.png)



# azkaban

![image-20191221131516317](C:\Users\app\AppData\Roaming\Typora\typora-user-images\image-20191221131516317.png)







# 启动关闭oozie服务

启动命令

cd /export/servers/oozie-4.1.0-cdh5.14.0

bin/oozied.sh start 

 

关闭命令

bin/oozied.sh stop

![img](file:///C:\Users\app\AppData\Local\Temp\ksohtml14256\wps1.jpg) 

启动的时候产生的 pid文件，如果是kill方式关闭进程 则需要删除该文件重新启动，否则再次启动会报错。





# 启动redis

![image-20191222134917993](C:\Users\app\AppData\Roaming\Typora\typora-user-images\image-20191222134917993.png)

# 启动kafka

 kafka-server-start.sh config/server.properties 

## 后台启动

nohup kafka-server-start.sh config/server.properties 2>&1 &





# 启动es

### 每次启动es都要执行

sudo  sysctl -w vm.max_map_count=262144   





## 第八步：启动ES服务

 

三台机器使用es用户执行以下命令启动es服务

nohup /export/servers/es/elasticsearch-6.7.0/bin/elasticsearch 2>&1 &

启动成功之后jsp即可看到es的服务进程，并且访问页面

http://node01:9200/?pretty

能够看到es启动之后的一些信息

注意：如果哪一台机器服务启动失败，那么就到哪一台机器的

/export/servers/es/elasticsearch-6.7.0/logs

这个路径下面去查看错误日志



## node01机器启动head服务

### node01启动elasticsearch-head插件

 cd /export/servers/es/elasticsearch-head/node_modules/grunt/bin/

进程前台启动命令

./grunt server

进程后台启动命令

nohup ./grunt server >/dev/null 2>&1 &

### 如何停止：elasticsearch-head进程

执行以下命令找到elasticsearch-head的插件进程，然后使用kill  -9  杀死进程即可

netstat -nltp | grep 9100

kill -9 8328





# 启动kibana

## node01服务器使用es用户执行以下命令启动kibana服务

cd /export/servers/es/kibana-6.7.0-linux-x86_64
nohup bin/kibana >/dev/null 2>&1 &

如何停止kibana进程：停止kibana服务进程

查看进程号

ps -ef | grep node

然后使用kill -9杀死进程即可

# 浏览器地址访问kibana服务

http://node01:5601







# Spark

启动 Spark Master 和 Slaves, 以及 HistoryServer

```
cd /export/servers/spark
sbin/start-all.sh
sbin/start-history-server.sh
```

![image-20191224023529407](C:\Users\app\AppData\Roaming\Typora\typora-user-images\image-20191224023529407.png)

bin/spark-submit \ --class spark-examples_2.11-2.2.0.jar \ --master spark://node01:7077,node02:7077,node03:7077 \ --executor-memory 1G \ --total-executor-cores 2 \ /export/servers/spark/examples/jars/spark-examples_2.11-2.2.3.jar \ 100





![image-20191225125634128](C:\Users\app\AppData\Roaming\Typora\typora-user-images\image-20191225125634128.png)







# Hbase

## 第七步：HBase集群启动

第一台机器执行以下命令进行启动

cd /export/servers/hbase-2.0.0

bin/start-hbase.sh



## 第八步页面访问

浏览器页面访问

http://node01:16010/master-status



## 1、进入HBase客户端命令操作界面

node01服务器执行以下命令进入hbase的shell客户端

cd /export/servers/hbase-2.0.0

bin/hbase shell





# NetCat

nc -lk 0.0.0.0 9999

nc localhost 9999





